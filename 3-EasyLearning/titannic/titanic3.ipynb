{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.处理数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def get_title(name):\n",
    "    if(pd.isnull(name)):\n",
    "        return 'Null'\n",
    "    title_search = re.search('([A-Za-z]+)\\.', name)\n",
    "    if title_search:\n",
    "        return title_search.group(1).lower()\n",
    "    else:\n",
    "        return 'None'\n",
    "    \n",
    "titles = {'mr': 1,\n",
    "          'mrs': 2, 'mme': 2,\n",
    "          'ms': 3, 'miss': 3, 'mlle': 3,\n",
    "          'don': 4, 'sir': 4, 'jonkheer': 4,\n",
    "          'major': 4, 'col': 4, 'dr': 4, 'master': 4, 'capt': 4,\n",
    "          'dona': 5, 'lady': 5, 'countness': 5,\n",
    "          'rev': 6}\n",
    "\n",
    "def get_train_data(path):\n",
    "    # 从CSV文件中读入数据\n",
    "    data = pd.read_csv(path)\n",
    "    \n",
    "    # 取部分特征字段用于分类，清洗Age等数据\n",
    "    data['Sex'] = data['Sex'].apply(lambda s: 1 if s == 'male' else 0)\n",
    "    mean_age = data[\"Age\"].mean()\n",
    "    data.loc[data.Age.isnull(), \"Age\"] = mean_age\n",
    "    \n",
    "    data['Title'] = data['Name'].apply(lambda name: titles.get(get_title(name)))\n",
    "    data['Honor'] = data['Title'].apply(lambda title: 1 if title == 4 or title == 5 else 0)\n",
    "    \n",
    "    data['Embarked'] = data['Embarked'].apply(lambda embarked: 1 if embarked == 'S' else embarked)\n",
    "    data['Embarked'] = data['Embarked'].apply(lambda embarked: 2 if embarked == 'C' else embarked)\n",
    "    data['Embarked'] = data['Embarked'].apply(lambda embarked: 3 if embarked == 'Q' else embarked)\n",
    "    \n",
    "    # 两种分类分别是幸存和死亡，‘Survived’字段是其中一种分类的标签，\n",
    "    # 新增‘Deceased’字段表示第二段分类的标签，取值为‘Survived’字段取非\n",
    "    data['Deceased'] = data['Survived'].apply(lambda s: int(not s))\n",
    "    \n",
    "    data = data.fillna(0)\n",
    "    data.info()\n",
    "    \n",
    "    return data\n",
    "\n",
    "def get_test_data(path):\n",
    "    # 从CSV文件中读入数据\n",
    "    data = pd.read_csv(path)\n",
    "    \n",
    "    # 取部分特征字段用于分类，清洗Age等数据\n",
    "    data['Sex'] = data['Sex'].apply(lambda s: 1 if s == 'male' else 0)\n",
    "    mean_age = data[\"Age\"].mean()\n",
    "    data.loc[data.Age.isnull(), \"Age\"] = mean_age\n",
    "    \n",
    "    data['Title'] = data['Name'].apply(lambda name: titles.get(get_title(name)))\n",
    "    data['Honor'] = data['Title'].apply(lambda title: 1 if title == 4 or title == 5 else 0)\n",
    "    \n",
    "    data['Embarked'] = data['Embarked'].apply(lambda embarked: 1 if embarked == 'S' else embarked)\n",
    "    data['Embarked'] = data['Embarked'].apply(lambda embarked: 2 if embarked == 'C' else embarked)\n",
    "    data['Embarked'] = data['Embarked'].apply(lambda embarked: 3 if embarked == 'Q' else embarked)\n",
    "    \n",
    "    data = data.fillna(0)\n",
    "    data.info()\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 15 columns):\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Name           891 non-null object\n",
      "Sex            891 non-null int64\n",
      "Age            891 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Ticket         891 non-null object\n",
      "Fare           891 non-null float64\n",
      "Cabin          891 non-null object\n",
      "Embarked       891 non-null float64\n",
      "Title          891 non-null float64\n",
      "Honor          891 non-null int64\n",
      "Deceased       891 non-null int64\n",
      "dtypes: float64(4), int64(8), object(3)\n",
      "memory usage: 104.5+ KB\n"
     ]
    }
   ],
   "source": [
    "data = get_train_data('../../../../dataset/titanic/train.csv')\n",
    "\n",
    "dataset_X = data[['Sex', 'Age', 'Pclass', 'SibSp', 'Parch', 'Fare', 'Honor', 'Embarked']].as_matrix()\n",
    "dataset_Y = data[['Survived']].as_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.初步处理数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 使用sklearn的train_test_split函数将标记数据切分为“训练数据集和验证集”\n",
    "# 将全部标记数据随机洗牌后切分，其中验证数据占20%，由test_size参数指定\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    dataset_X, dataset_Y, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.使用SkFlow建立模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\AkiKan\\AppData\\Local\\Temp\\tmppplio0oi\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\AkiKan\\\\AppData\\\\Local\\\\Temp\\\\tmppplio0oi', '_environment': 'local', '_save_summary_steps': 100, '_is_chief': True, '_keep_checkpoint_max': 5, '_evaluation_master': '', '_task_type': None, '_master': '', '_save_checkpoints_steps': None, '_num_worker_replicas': 0, '_session_config': None, '_keep_checkpoint_every_n_hours': 10000, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_tf_random_seed': None, '_log_step_count_steps': 100, '_task_id': 0, '_num_ps_replicas': 0, '_save_checkpoints_secs': 600, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x00000283595FEF60>}\n",
      "WARNING:tensorflow:From <ipython-input-4-babaa07fee47>:6: calling BaseEstimator.fit (from tensorflow.contrib.learn.python.learn.estimators.estimator) with x is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:From <ipython-input-4-babaa07fee47>:6: calling BaseEstimator.fit (from tensorflow.contrib.learn.python.learn.estimators.estimator) with y is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
      "WARNING:tensorflow:Casting <dtype: 'int64'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'int64'> labels to bool.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into C:\\Users\\AkiKan\\AppData\\Local\\Temp\\tmppplio0oi\\model.ckpt.\n",
      "INFO:tensorflow:step = 1, loss = 0.6931462\n",
      "INFO:tensorflow:global_step/sec: 164.374\n",
      "INFO:tensorflow:step = 101, loss = 0.49609718 (0.609 sec)\n",
      "INFO:tensorflow:global_step/sec: 177.222\n",
      "INFO:tensorflow:step = 201, loss = 0.46641332 (0.564 sec)\n",
      "INFO:tensorflow:global_step/sec: 153.468\n",
      "INFO:tensorflow:step = 301, loss = 0.45557588 (0.652 sec)\n",
      "INFO:tensorflow:global_step/sec: 151.801\n",
      "INFO:tensorflow:step = 401, loss = 0.4496471 (0.658 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 500 into C:\\Users\\AkiKan\\AppData\\Local\\Temp\\tmppplio0oi\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.4459477.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearClassifier(params={'joint_weights': False, 'gradient_clip_norm': None, 'optimizer': None, 'head': <tensorflow.contrib.learn.python.learn.estimators.head._BinaryLogisticHead object at 0x000002835506EB70>, 'feature_columns': [_RealValuedColumn(column_name='', dimension=8, default_value=None, dtype=tf.float64, normalizer=None)]})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow.contrib.learn as skflow\n",
    "from sklearn import metrics\n",
    "\n",
    "feature_cols = skflow.infer_real_valued_columns_from_input(X_train)\n",
    "classifier = skflow.LinearClassifier(feature_columns=feature_cols, n_classes=2)\n",
    "classifier.fit(X_train, y_train, steps=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Programming\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py:381: calling LinearClassifier.predict (from tensorflow.contrib.learn.python.learn.estimators.linear) with outputs=None is deprecated and will be removed after 2017-03-01.\n",
      "Instructions for updating:\n",
      "Please switch to predict_classes, or set `outputs` argument.\n",
      "WARNING:tensorflow:From D:\\Programming\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\linear.py:563: calling BaseEstimator.predict (from tensorflow.contrib.learn.python.learn.estimators.estimator) with x is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\AkiKan\\AppData\\Local\\Temp\\tmppplio0oi\\model.ckpt-500\n",
      "<generator object _as_iterable at 0x000002835B1342B0>\n"
     ]
    }
   ],
   "source": [
    "# 预测结果有些问题\n",
    "y_pred = classifier.predict(X_test)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.000000\n"
     ]
    }
   ],
   "source": [
    "accuracy = metrics.accuracy_score(y_test, y_test)\n",
    "print(\"Accuracy: %f\" % accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.TFLearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 649  | total loss: \u001b[1m\u001b[32m0.47325\u001b[0m\u001b[0m | time: 0.044s\n",
      "| Adam | epoch: 050 | loss: 0.47325 -- iter: 768/801\n",
      "Training Step: 650  | total loss: \u001b[1m\u001b[32m0.47812\u001b[0m\u001b[0m | time: 1.050s\n",
      "| Adam | epoch: 050 | loss: 0.47812 | val_loss: 0.48891 -- iter: 801/801\n",
      "--\n",
      "INFO:tensorflow:E:\\Document\\administer\\Python Scripts\\git\\DL-Test\\3-EasyLearning\\titannic\\ckpt_dir\\model.ckpt is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Accuracy on train set: 0.794612795\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tflearn\n",
    "\n",
    "train_data = get_train_data('../../../../dataset/titanic/train.csv')\n",
    "X = train_data[['Sex', 'Age', 'Pclass', 'SibSp', 'Parch', 'Fare', 'Embarked', 'Title', 'Honor']].as_matrix()\n",
    "Y = train_data[['Deceased', 'Survived']].as_matrix()\n",
    "\n",
    "# mkdir checkpoint path\n",
    "ckpt_dir = './ckpt_dir'\n",
    "if not os.path.exists(ckpt_dir):\n",
    "    os.makedirs(ckpt_dir)\n",
    "    \n",
    "# 定义分类模型\n",
    "x_input = tflearn.input_data([None, X.shape[1]])\n",
    "y_pred = tflearn.layers.fully_connected(x_input, 2, activation='softmax')\n",
    "net = tflearn.regression(y_pred)\n",
    "model = tflearn.DNN(net)\n",
    "\n",
    "# 读取模型存档\n",
    "# if os.path.isfile(os.path.join(ckpt_dir, 'model.cpkt')):\n",
    "#     model.load(os.path.join(ckpt_dir, 'model.ckpt'))\n",
    "# 训练    \n",
    "model.fit(X, Y, validation_set=0.1, n_epoch=50)\n",
    "# 存储模型参数\n",
    "model.save(os.path.join(ckpt_dir, 'model.ckpt'))\n",
    "# 查看模型在训练集上的准确度\n",
    "metric = model.evaluate(X, Y)\n",
    "print('Accuracy on train set: %.9f' % metric[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 13 columns):\n",
      "PassengerId    418 non-null int64\n",
      "Pclass         418 non-null int64\n",
      "Name           418 non-null object\n",
      "Sex            418 non-null int64\n",
      "Age            418 non-null float64\n",
      "SibSp          418 non-null int64\n",
      "Parch          418 non-null int64\n",
      "Ticket         418 non-null object\n",
      "Fare           418 non-null float64\n",
      "Cabin          418 non-null object\n",
      "Embarked       418 non-null int64\n",
      "Title          418 non-null int64\n",
      "Honor          418 non-null int64\n",
      "dtypes: float64(2), int64(8), object(3)\n",
      "memory usage: 42.5+ KB\n"
     ]
    }
   ],
   "source": [
    "# 读取测试数据，并进行预测\n",
    "test_data = get_test_data('../../../../dataset/titanic/test.csv')\n",
    "X = test_data[['Sex', 'Age', 'Pclass', 'SibSp', 'Parch', 'Fare', 'Embarked', 'Title', 'Honor']].as_matrix()\n",
    "predictions = np.argmax(model.predict(X), axis=1)\n",
    "\n",
    "# 构建提交结果的数据结构，并将结果存为csv文件\n",
    "submission = pd.DataFrame({\"PassengerId\": test_data[\"PassengerId\"], \"Survived\": predictions})\n",
    "submission.to_csv(\"../../../../dataset/titanic/titanic_submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
