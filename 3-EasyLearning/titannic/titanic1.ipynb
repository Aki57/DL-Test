{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.处理数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Name           891 non-null object\n",
      "Sex            891 non-null object\n",
      "Age            714 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Ticket         891 non-null object\n",
      "Fare           891 non-null float64\n",
      "Cabin          204 non-null object\n",
      "Embarked       889 non-null object\n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.6+ KB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# 从CSV文件中读入数据\n",
    "data = pd.read_csv('../../../../dataset/titanic/train.csv')\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 取部分特征字段用于分类，清洗Age等数据\n",
    "data['Sex'] = data['Sex'].apply(lambda s: 1 if s == 'male' else 0)\n",
    "\n",
    "mean_age = data[\"Age\"].mean()\n",
    "data.loc[data.Age.isnull(), \"Age\"] = mean_age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_title(name):\n",
    "    if(pd.isnull(name)):\n",
    "        return 'Null'\n",
    "    title_search = re.search('([A-Za-z]+)\\.', name)\n",
    "    if title_search:\n",
    "        return title_search.group(1).lower()\n",
    "    else:\n",
    "        return 'None'\n",
    "    \n",
    "titles = {'mr': 1,\n",
    "          'mrs': 2, 'mme': 2,\n",
    "          'ms': 3, 'miss': 3, 'mlle': 3,\n",
    "          'don': 4, 'sir': 4, 'jonkheer': 4,\n",
    "          'major': 4, 'col': 4, 'dr': 4, 'master': 4, 'capt': 4,\n",
    "          'dona': 5, 'lady': 5, 'countness': 5,\n",
    "          'rev': 6}\n",
    "data['Title'] = data['Name'].apply(lambda name: titles.get(get_title(name)))\n",
    "data['Honor'] = data['Title'].apply(lambda title: 1 if title == 4 or title == 5 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = data.fillna(0)\n",
    "dataset_X = data[['Sex', 'Age', 'Pclass', 'SibSp', 'Parch', 'Fare', 'Honor']]\n",
    "dataset_X = dataset_X.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 15 columns):\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Name           891 non-null object\n",
      "Sex            891 non-null int64\n",
      "Age            891 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Ticket         891 non-null object\n",
      "Fare           891 non-null float64\n",
      "Cabin          891 non-null object\n",
      "Embarked       891 non-null object\n",
      "Title          891 non-null float64\n",
      "Honor          891 non-null int64\n",
      "Deceased       891 non-null int64\n",
      "dtypes: float64(3), int64(8), object(4)\n",
      "memory usage: 104.5+ KB\n"
     ]
    }
   ],
   "source": [
    "# 两种分类分别是幸存和死亡，‘Survived’字段是其中一种分类的标签，\n",
    "# 新增‘Deceased’字段表示第二段分类的标签，取值为‘Survived’字段取非\n",
    "data['Deceased'] = data['Survived'].apply(lambda s: int(not s))\n",
    "dataset_Y = data[['Deceased', 'Survived']]\n",
    "dataset_Y = dataset_Y.as_matrix()\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.初步处理数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 使用sklearn的train_test_split函数将标记数据切分为“训练数据集和验证集”\n",
    "# 将全部标记数据随机洗牌后切分，其中验证数据占20%，由test_size参数指定\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    dataset_X, dataset_Y, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(712, 7)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.建立模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0000, total loss = 2362.563125918\n",
      "Epoch: 0010, total loss = 628.702243420\n",
      "Epoch: 0020, total loss = 580.654461581\n",
      "Epoch: 0030, total loss = 544.563262179\n",
      "Epoch: 0040, total loss = 516.736007599\n",
      "Epoch: 0050, total loss = 495.132999380\n",
      "Epoch: 0060, total loss = 478.375834124\n",
      "Epoch: 0070, total loss = 465.355373776\n",
      "Epoch: 0080, total loss = 455.220854513\n",
      "Epoch: 0090, total loss = 447.276141106\n",
      "Training complete!\n",
      "Accuracy on validation set: 0.687150836\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# 声明输入数据占位符\n",
    "# shape参数的第一个元素为None，表示可以同时放入任意条记录\n",
    "with tf.name_scope('input'):\n",
    "    X = tf.placeholder(tf.float32, shape=[None, 7], name='input_x')\n",
    "    y = tf.placeholder(tf.float32, shape=[None, 2], name='input_y')\n",
    "\n",
    "with tf.name_scope('classifier'):\n",
    "    # 声明变量\n",
    "    W = tf.Variable(tf.random_normal([7, 2]), name='weights')\n",
    "    b = tf.Variable(tf.zeros([2]), name='bias')\n",
    "    y_pred = tf.nn.softmax(tf.matmul(X, W) + b)\n",
    "    \n",
    "    # 添加直方图参数概要记录算子\n",
    "    tf.summary.histogram('weights', W)\n",
    "    tf.summary.histogram('bias',b)\n",
    "\n",
    "with tf.name_scope('cost'):\n",
    "    # 使用交叉熵作为代价函数\n",
    "    cross_entropy = - tf.reduce_sum(y * tf.log(y_pred + 1e-10))\n",
    "    # 批量样本的代价值为所有样本交叉熵的平均值\n",
    "    cost = tf.reduce_mean(cross_entropy)\n",
    "    # 添加损失函数标量概要\n",
    "    tf.summary.scalar('loss', cost)\n",
    "\n",
    "# 使用随机梯度下降算法优化器来最小化代价，系统自动构建反向传播部分的计算图\n",
    "train_op = tf.train.GradientDescentOptimizer(0.0002).minimize(cost)\n",
    "\n",
    "with tf.name_scope('accuracy'):\n",
    "    correct_pred = tf.equal(tf.argmax(y, 1), tf.argmax(y_pred, 1))\n",
    "    acc_op = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "    tf.summary.scalar('accuracy', acc_op)\n",
    "\n",
    "# 保存模型\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # 创建概要写入操作\n",
    "    # Tensorboard可通过命令‘tensorboard --logdir=./logs’来启动\n",
    "    writer = tf.summary.FileWriter('./logs', sess.graph)\n",
    "    merged = tf.summary.merge_all()\n",
    "    \n",
    "    # 初始化所有变量，必须最先执行\n",
    "    tf.global_variables_initializer().run()\n",
    "    # 以下为训练迭代，迭代10轮\n",
    "    for epoch in range(100):\n",
    "        total_loss = 0.\n",
    "        for i in range(len(X_train)):\n",
    "            # 通过session.run接口触发运行\n",
    "            _, loss = sess.run([train_op, cost], feed_dict = {X: [X_train[i]], y: [y_train[i]]})\n",
    "            total_loss += loss\n",
    "        \n",
    "        summary, accuracy = sess.run([merged, acc_op], feed_dict = {X: X_train, y: y_train})\n",
    "        writer.add_summary(summary, epoch)\n",
    "        \n",
    "        if(epoch%10 == 0):\n",
    "            print('Epoch: %04d, total loss = %.9f' % (epoch, total_loss))\n",
    "            saver.save(sess,\"./mymodel.ckpt\", global_step=epoch)\n",
    "    \n",
    "    writer.close()\n",
    "    saver.save(sess,\"./mymodel.ckpt\")\n",
    "    print('Training complete!')\n",
    "    \n",
    "    # 评估校验数据集上的准确率\n",
    "    pred = sess.run(y_pred, feed_dict={X: X_test})\n",
    "    correct = np.equal(np.argmax(pred, 1), np.argmax(y_test, 1))\n",
    "    accuracy = np.mean(correct.astype(np.float32))\n",
    "    print(\"Accuracy on validation set: %.9f\" % accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./mymodel.ckpt\n"
     ]
    }
   ],
   "source": [
    "# 读入测试数据集并完成预处理\n",
    "testdata = pd.read_csv('../../../../dataset/titanic/test.csv')\n",
    "\n",
    "mean_age = testdata[\"Age\"].mean()\n",
    "testdata.loc[testdata.Age.isnull(), \"Age\"] = mean_age\n",
    "\n",
    "testdata = testdata.fillna(0)\n",
    "testdata['Sex'] = testdata['Sex'].apply(lambda s:1 if s == 'male' else 0)\n",
    "\n",
    "testdata['Title'] = testdata['Name'].apply(lambda name: titles.get(get_title(name)))\n",
    "testdata['Honor'] = testdata['Title'].apply(lambda title: 1 if title == 4 or title == 5 else 0)\n",
    "\n",
    "X_test = testdata[['Sex', 'Age', 'Pclass', 'SibSp', 'Parch', 'Fare', 'Honor']]\n",
    "\n",
    "# 开启session进行预测\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, './mymodel.ckpt')\n",
    "    # 正向传播计算\n",
    "    predictions = np.argmax(sess.run(y_pred, feed_dict={X: X_test}), 1)\n",
    "    # 构建提交结果的数据结构，并将结果存为csv文件\n",
    "    submission = pd.DataFrame({\"PassengerId\": testdata[\"PassengerId\"], \"Survived\": predictions})\n",
    "    submission.to_csv(\"../../../../dataset/titanic/titanic_submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
